{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b86cef",
   "metadata": {},
   "source": [
    "# Visual Reasoning Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b4cc32",
   "metadata": {},
   "source": [
    "1. Data preprocessing 어떻게 하면될까?\n",
    " - Image feature를 resnet으로 미리 추출해둘까? --> baseline돌리기 까다로움\n",
    " - DataLoader 구성을 어떻게하면 좋을까? --> DataSet class 안에서 feature를 return 할까? 아니면 ResNet을 밖에둘까\n",
    "\n",
    "\n",
    "2. Baseline Model 설계를 어떻게?\n",
    " - Encoder: image encoding 어떻게 하면 될까? Answer Image 3개를 한꺼번에 encoding? 혹은 각각 encoding 한 후 Weight Sum??\n",
    " - Decoder: Answer 후보 중 정답후보를 어떻게 고를까? Similarity 기준? KL 같은 분포기준? Attention 기반 Scoring??\n",
    "\n",
    "\n",
    "3. SOTA Model 설계를 어떻게? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8025aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:19:07.936060Z",
     "start_time": "2022-07-26T09:19:07.932095Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf287b82",
   "metadata": {},
   "source": [
    "## 1. Import all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5de51e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:19:10.185051Z",
     "start_time": "2022-07-26T09:19:08.515128Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.font_manager as fm\n",
    "#fm.get_fontconfig_fonts()\n",
    "#font_location = './NanumGothic.ttf'\n",
    "#font_location = 'C:/Windows/Fonts/NanumGothic.ttf' # For Windows\n",
    "#font_name = fm.FontProperties(fname=font_location).get_name()\n",
    "#matplotlib.rc('font', family=font_name)\n",
    "\n",
    "%matplotlib inline\n",
    "# 브라우저에서 바로 이미지를 그린다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316390cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:19:10.206377Z",
     "start_time": "2022-07-26T09:19:10.197588Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "nrows,ncols=6,15\n",
    "fig,ax = plt.subplots(nrows,ncols,figsize=(15,6))\n",
    "plt.subplots_adjust(wspace=0, hspace=0) \n",
    "for i,j in enumerate(malignant[:nrows*ncols]):\n",
    "    fname = os.path.join(imgpath ,j +'.tif')\n",
    "    img = Image.open(fname)\n",
    "    idcol = ImageDraw.Draw(img)\n",
    "    idcol.rectangle(((0,0),(95,95)),outline='red')\n",
    "    plt.subplot(nrows, ncols, i+1) \n",
    "    plt.imshow(np.array(img))\n",
    "    plt.axis('off')\n",
    "    \n",
    "import plotly.express as px\n",
    "\n",
    "# Create grid of sample images \n",
    "grid_size=30\n",
    "rnd_inds=np.random.randint(0,len(train_ts),grid_size)\n",
    "print(\"image indices:\",rnd_inds)\n",
    "\n",
    "x_grid_train=[train_ts[i][0] for i in rnd_inds]\n",
    "y_grid_train=[train_ts[i][1] for i in rnd_inds]\n",
    "\n",
    "x_grid_train=utils.make_grid(x_grid_train, nrow=10, padding=2)\n",
    "print(x_grid_train.shape)\n",
    "    \n",
    "plot_img(x_grid_train,y_grid_train,'Training Subset Examples')\n",
    "image indices: [1438  355 2681 1007 2970 2925  605 1739  270 1641 1080  786 1840   62\n",
    " 2633  734 1712  511 2681 2973  180 2601  500 1959  869    3 2359 3153\n",
    "  345 1307]\n",
    "torch.Size([3, 146, 482])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c84fc7",
   "metadata": {},
   "source": [
    "## 2. Preparation of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e88e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:19:10.626840Z",
     "start_time": "2022-07-26T09:19:10.217043Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, args=None):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.distributed = False\n",
    "        self.gpu_id = \"0,1\"\n",
    "        self.HOME_DIR = \"./datasets/\"\n",
    "        self.TASK_NAME = \"similarity1/\"\n",
    "        self.FOLDER_NAME = \"000003/\"\n",
    "        self.IMAGE_LIST = [\n",
    "                \"0d73dee440ef4291ae926fb5cb4ec55e.jpg\", \n",
    "                \"18f827e0d01742d495d3ecbaffb6255a.jpg\", \n",
    "                \"1b243a095866423da8f4a8f19d78ecf4.jpg\",\n",
    "                \"4db9fa5bd947497d91bffd8de3b07e6e.jpg\",\n",
    "                \"95ac10e3608e4abba9407a2a1cae2883.jpg\",\n",
    "                \"a05e9630fd754a249b1fba0be5f386ed.jpg\",\n",
    "                \"ea1f8a29ba464af4b2b393d4bb50d7c0.jpg\"\n",
    "             ]\n",
    "        self.JSON_NAME = \"000003\"+\".json\"\n",
    "        self.input_dim = 512\n",
    "        self.mlp_hidden = 1024\n",
    "\n",
    "\n",
    "config = Config()\n",
    "a_image_file = config.HOME_DIR+config.TASK_NAME+config.FOLDER_NAME+config.IMAGE_LIST[0]\n",
    "a_image = plt.imread(a_image_file)\n",
    "plt.imshow(a_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7b3930",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:19:10.650558Z",
     "start_time": "2022-07-26T09:19:10.640587Z"
    }
   },
   "outputs": [],
   "source": [
    "def mixup(a1, a2):\n",
    "\n",
    "    n, p = 1, .5\n",
    "    new_answer = np.random.binomial(n, p, 1) ## Generate a new answer\n",
    "    new_answer1 = a1 if new_answer==0 else a2\n",
    "    new_answer2 = a2 if new_answer==0 else a1\n",
    "\n",
    "    return pd.Series([new_answer1, new_answer2, new_answer])\n",
    "\n",
    "def get_data(config):\n",
    "    \n",
    "    home_dir = config.HOME_DIR\n",
    "    task_name = config.TASK_NAME\n",
    "    dir_list = os.listdir(home_dir+task_name)\n",
    "    sample_list = []\n",
    "    \n",
    "    for directory in dir_list:\n",
    "        FOLDER_NAME = directory+\"/\"\n",
    "        JSON_NAME = directory+\".json\"\n",
    "        FILE_PATH = home_dir+task_name+FOLDER_NAME\n",
    "        a_data = json.load(open(FILE_PATH+JSON_NAME))\n",
    "        a_data[\"file_path\"] = FILE_PATH\n",
    "        a_data[\"answer1\"] = [a_data[\"Answers\"][0]]\n",
    "        a_data[\"answer2\"] = [a_data[\"Answers\"][1]]\n",
    "        del a_data[\"Answers\"]\n",
    "        sample_list.append(a_data)\n",
    "        \n",
    "        df = pd.DataFrame(sample_list)\n",
    "\n",
    "    df[['answer1', 'answer2', 'correct_answer_group_ID']] = df.apply(lambda x: mixup(x[\"answer1\"], x[\"answer2\"]), axis = 1)\n",
    "    df.drop(df[df[\"doc_id\"] == \"000769\"].index, inplace=True)\n",
    "    df.drop(df[df[\"doc_id\"] == \"000256\"].index, inplace=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def get_img_argumentation():\n",
    "    #이미지 전처리를 위한 이미지 크기 변환 및 각도조정을 위한 transform 선언\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((356, 356)),\n",
    "            transforms.RandomCrop((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0333692",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:19:10.669073Z",
     "start_time": "2022-07-26T09:19:10.661501Z"
    }
   },
   "outputs": [],
   "source": [
    "class Similarity1_Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, df, config=None, transform=None):\n",
    "        self.df = df\n",
    "        self.config = config\n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.df.iloc[idx]\n",
    "        \n",
    "        target = sample[\"correct_answer_group_ID\"][0]\n",
    "        category = sample[\"category\"]\n",
    "        q_img = sample[\"file_path\"] + sample[\"Questions\"][0][\"images\"][0][\"image_url\"]\n",
    "        a1_img = [sample[\"file_path\"] + ans_img[\"image_url\"] for ans_img in sample[\"answer1\"][0][\"images\"]]\n",
    "        a2_img = [sample[\"file_path\"] + ans_img[\"image_url\"] for ans_img in sample[\"answer2\"][0][\"images\"]]\n",
    "        \n",
    "        q_img_feature = Image.open(q_img).convert('RGB')  #이미지 데이터를 RGB형태로 읽음 \n",
    "        q_img_feature = self.transform(q_img_feature)  #이미지 데이터의 크기 및 각도등을 변경\n",
    "        \n",
    "        a1_img_feature = [self.transform(Image.open(img).convert('RGB')) for img in a1_img]\n",
    "        a2_img_feature = [self.transform(Image.open(img).convert('RGB')) for img in a2_img]\n",
    "        \n",
    "        return {\n",
    "            \"target\": target,\n",
    "            \"q_img\": q_img_feature,\n",
    "            \"a1_imgs\": a1_img_feature,\n",
    "            \"a2_imgs\": a2_img_feature\n",
    "        }\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007718eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:19:11.169485Z",
     "start_time": "2022-07-26T09:19:11.155693Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_sequential(in_channels, out_channels, *args, **kwargs):\n",
    "    return nn.Sequential(nn.Conv2d(in_channels, out_channels, *args, **kwargs),\n",
    "           nn.BatchNorm2d(out_channels),\n",
    "           nn.ReLu(),\n",
    "           nn.MaxPool2d(*args, **kwargs))\n",
    "\n",
    "class VRSimilarity(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(VRSimilarity, self).__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        self.backborne = torchvision.models.resnet50(pretrained=True)\n",
    "        self.backborne.fc = nn.Linear(self.backborne.fc.in_features, self.config.input_dim)\n",
    "        self.fc = nn.Sequential(\n",
    "                    nn.Linear(self.config.input_dim*4, self.config.mlp_hidden),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.2),\n",
    "                    nn.Linear(self.config.mlp_hidden, self.config.mlp_hidden),\n",
    "        )\n",
    "        self.classfier = nn.Sequential(\n",
    "                    nn.Linear(self.config.mlp_hidden*2, self.config.mlp_hidden),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.2),\n",
    "                    nn.Linear(self.config.mlp_hidden, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, samples):\n",
    "        \n",
    "        #Question Image Feature\n",
    "        q = self.backborne(samples[\"q_img\"])\n",
    "        \n",
    "        #Answer1 Image Feature\n",
    "        a1_img1 = self.backborne(samples[\"a1_imgs\"][0])\n",
    "        a1_img2 = self.backborne(samples[\"a1_imgs\"][1])\n",
    "        a1_img3 = self.backborne(samples[\"a1_imgs\"][2])\n",
    "        \n",
    "        #Answer2 Image Feature\n",
    "        a2_img1 = self.backborne(samples[\"a2_imgs\"][0])\n",
    "        a2_img2 = self.backborne(samples[\"a2_imgs\"][1])\n",
    "        a2_img3 = self.backborne(samples[\"a2_imgs\"][2])\n",
    "        \n",
    "        q_a1 = torch.cat([q, a1_img1, a1_img2, a1_img3], axis=1)\n",
    "        q_a2 = torch.cat([q, a2_img1, a2_img2, a2_img3], axis=1)\n",
    "        \n",
    "        q_a1_logit = self.fc(q_a1)\n",
    "        q_a2_logit = self.fc(q_a2)\n",
    "        \n",
    "        q_a1_a2_logit = torch.cat([q_a1_logit, q_a2_logit], axis=1)\n",
    "        logit = self.classfier(q_a1_a2_logit)\n",
    "        \n",
    "        return logit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32563ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:19:11.613678Z",
     "start_time": "2022-07-26T09:19:11.602254Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_fn(model, train_loader, optimizer, loss_fn, config):\n",
    "    \n",
    "    total_count_correct = 0\n",
    "    total_num_example = 0\n",
    "    total_loss = []\n",
    "    \n",
    "    model.train()\n",
    "    device = config.device\n",
    "    \n",
    "    for batch in tqdm(train_loader):          \n",
    "        \n",
    "        #Question Image Feature\n",
    "        batch[\"q_img\"] = batch[\"q_img\"].to(device)\n",
    "        \n",
    "        #Answer1 Image Feature\n",
    "        batch[\"a1_imgs\"][0] = batch[\"a1_imgs\"][0].to(device)\n",
    "        batch[\"a1_imgs\"][1] = batch[\"a1_imgs\"][1].to(device)\n",
    "        batch[\"a1_imgs\"][2] = batch[\"a1_imgs\"][2].to(device)\n",
    "        \n",
    "        #Answer2 Image Feature\n",
    "        batch[\"a2_imgs\"][0] = batch[\"a2_imgs\"][0].to(device)\n",
    "        batch[\"a2_imgs\"][1] = batch[\"a2_imgs\"][1].to(device)\n",
    "        batch[\"a2_imgs\"][2] = batch[\"a2_imgs\"][2].to(device)\n",
    "        logit = model(batch)\n",
    "\n",
    "        target = batch[\"target\"].long().to(device)\n",
    "        loss = loss_fn(logit, target)\n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "        predicted = logit.argmax(dim=1, keepdim=True).squeeze()\n",
    "        total_count_correct = total_count_correct + torch.sum(predicted == target).item()\n",
    "        total_num_example = total_num_example + target.size(0)\n",
    "\n",
    "        print(logit)\n",
    "        print(predicted)\n",
    "        print(target)\n",
    "        print(predicted == target)\n",
    "        print(loss)\n",
    "\n",
    "        print(\"total_count_correct\", total_count_correct)\n",
    "        print(\"total_num_example\", total_num_example)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"LOSS:\", str(sum(total_loss)/total_num_example) + \" Accuracy: \" + str(total_count_correct/total_num_example) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa88af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:19:30.110420Z",
     "start_time": "2022-07-26T09:19:12.766327Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "df = get_data(config)\n",
    "train_df, test_df = train_test_split(df)\n",
    "transform = get_img_argumentation()\n",
    "train_datasets = Similarity1_Dataset(train_df, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_datasets, batch_size=48)\n",
    "\n",
    "vrs1_model = VRSimilarity(config)\n",
    "#vrs1_model = torch.nn.DataParallel(vrs1_model)\n",
    "vrs1_model = vrs1_model.to(config.device)\n",
    "if config.distributed:\n",
    "    #vrs1_model = torch.nn.parallel.DistributedDataParallel(vrs1_model, device_ids=[config.gpu])    \n",
    "    vrs1_model = torch.nn.parallel.DistributedDataParallel(vrs1_model)    \n",
    "\n",
    "optimizer = torch.optim.Adam(vrs1_model.parameters(), lr=0.008)\n",
    "#loss_fn = nn.BCELoss()\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083f86b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:25:51.623596Z",
     "start_time": "2022-07-26T09:19:30.220575Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx in range(200):\n",
    "    train_fn(vrs1_model, train_loader, optimizer, loss_fn, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1b326",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T07:05:39.569750Z",
     "start_time": "2022-07-26T07:05:39.560952Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaef101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T07:05:42.691326Z",
     "start_time": "2022-07-26T07:05:42.652878Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec85f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
